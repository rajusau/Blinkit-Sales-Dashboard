{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickcommerce_simulation.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import calendar\n",
    "import logging\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 09:50:18,333 INFO:Year-end stock levels bumped for 2022\n",
      "2025-06-19 09:51:46,889 INFO:Year-end stock levels bumped for 2023\n",
      "2025-06-19 09:53:44,309 INFO:Year-end stock levels bumped for 2024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date, time\n",
    "import random\n",
    "import os\n",
    "import calendar\n",
    "import logging\n",
    "from faker import Faker\n",
    "\n",
    "# -----------------------\n",
    "# Logging Setup\n",
    "# -----------------------\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "# -----------------------\n",
    "# Global Setup & Constants\n",
    "# -----------------------\n",
    "np.random.seed(150)\n",
    "random.seed(150)\n",
    "fake = Faker('en_IN')\n",
    "\n",
    "DEFAULT_START_DATE = '2022-01-01'\n",
    "\n",
    "# Configurable feedback data path\n",
    "FEEDBACK_DATA_PATH = os.environ.get(\n",
    "    'FEEDBACK_DATA_PATH',\n",
    "    r\"C:\\DATA SCIENCE ROADMAP\\PROJECTS\\Apna Quick Commerce Project (PowerBI+MySQL)\\New data\\realistic_feedback.csv\"\n",
    ")\n",
    "\n",
    "# File paths\n",
    "ORDERS_CSV = 'Apna_orders.csv'\n",
    "ORDER_ITEMS_CSV = 'Apna_order_items.csv'\n",
    "DELIVERY_PERFORMANCE_CSV = 'Apna_delivery_performance.csv'\n",
    "CUSTOMER_FEEDBACK_CSV = 'Apna_customer_feedback.csv'\n",
    "STATIC_CUSTOMERS_CSV = 'Apna_customers.csv'\n",
    "STATIC_PRODUCTS_CSV = 'Apna_products.csv'\n",
    "MARKETING_PERFORMANCE_CSV = 'Apna_marketing_performance.csv'\n",
    "INVENTORY_CSV = 'Apna_inventory.csv'\n",
    "\n",
    "# Load realistic feedback data\n",
    "try:\n",
    "    realistic_feedback_df = pd.read_csv(FEEDBACK_DATA_PATH)\n",
    "    # Expecting columns: id, rating, feedback_text, feedback_category, sentiment, order_status\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading feedback data: {e}\")\n",
    "    realistic_feedback_df = pd.DataFrame(\n",
    "        columns=['id','rating', 'feedback_text', 'feedback_category', 'sentiment', 'order_status']\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# Define Base & Cancel Categories\n",
    "# -----------------------\n",
    "base_categories = [\n",
    "    'Product Quality',\n",
    "    'Customer Service',\n",
    "    'Fast Delivery',\n",
    "    'Slow Delivery',\n",
    "    'App Experience',\n",
    "    'Price Concern',\n",
    "    'Packaging Issue',\n",
    "    'Payment Trouble',\n",
    "    'Delivery Concern'\n",
    "]\n",
    "\n",
    "cancel_reasons = [\n",
    "    'Product Unavailable',\n",
    "    'Customer Cancellation',\n",
    "    'Payment Issue',\n",
    "    'Changed Mind',\n",
    "    'Found Cheaper Alternative',\n",
    "    'Price Issue',\n",
    "    'Stock Issue'\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Expanded City, Delivery Partner & Pincode Settings\n",
    "# -----------------------\n",
    "CITY_LIST = [\n",
    "    \"Agra\",\"Ahmedabad\",\"Allahabad\",\"Amritsar\",\"Asansol\",\"Bengaluru\",\"Bhopal\",\"Bhubaneswar\",\"Chandigarh\",\"Chennai\",\"Dehradun\",\"Delhi\",\"Goa\",\"Guwahati\",\"Howrah\",\"Hyderabad\",\"Indore\",\"Jaipur\",\"Jalandhar\",\"Kanpur\",\"Kolkata\",\"Kota\",\"Lucknow\",\"Ludhiana\",\"Mumbai\",\"Mysuru\",\"Nagpur\",\"Nasik\",\"New Delhi\",\"Pune\",\"Rajkot\",\"Ranchi\",\"Surat\",\"Tiruchirapalli\",\"Vadodara\",\"Varanasi\",\"Vijayawada\" \n",
    "]\n",
    "\n",
    "CITY_WEIGHTS = [5, 15, 5, 5, 5, 20, 10, 8, 8, 20, 5, 20, 5, 8, 5, 20, 8, 10, 5, 10, 15, 5, 10, 10, 20, 5, 8, 8, 20, 15, 5, 5, 15, 5, 8, 5, 5]\n",
    "\n",
    "\n",
    "city_delivery_partners = {\"Agra\": list(range(200, 250)), \"Ahmedabad\": list(range(250, 300)), \"Allahabad\": list(range(300, 350)), \"Amritsar\": list(range(350, 400)), \"Asansol\": list(range(400, 450)), \"Bengaluru\": list(range(450, 500)), \"Bhopal\": list(range(500, 550)), \"Bhubaneswar\": list(range(550, 600)), \"Chandigarh\": list(range(600, 650)), \"Chennai\": list(range(650, 700)), \"Dehradun\": list(range(700, 750)), \"Delhi\": list(range(750, 800)), \"Goa\": list(range(800, 850)), \"Guwahati\": list(range(850, 900)), \"Howrah\": list(range(900, 950)), \"Hyderabad\": list(range(950, 1000)), \"Indore\": list(range(1000, 1050)), \"Jaipur\": list(range(1050, 1100)), \"Jalandhar\": list(range(1100, 1150)), \"Kanpur\": list(range(1150, 1200)), \"Kolkata\": list(range(1200, 1250)), \"Kota\": list(range(1250, 1300)), \"Lucknow\": list(range(1300, 1350)), \"Ludhiana\": list(range(1350, 1400)), \"Mumbai\": list(range(1400, 1450)), \"Mysuru\": list(range(1450, 1500)), \"Nagpur\": list(range(1500, 1550)), \"Nasik\": list(range(1550, 1600)), \"New Delhi\": list(range(1600, 1650)), \"Pune\": list(range(1650, 1700)), \"Rajkot\": list(range(1700, 1750)), \"Ranchi\": list(range(1750, 1800)), \"Surat\": list(range(1800, 1850)), \"Tiruchirapalli\": list(range(1850, 1900)), \"Vadodara\": list(range(1900, 1950)), \"Varanasi\": list(range(1950, 2000)), \"Vijayawada\": list(range(2000, 2050))}\n",
    "\n",
    "store_ids = {\"Agra\": list(range(20000,20050)), \"Ahmedabad\": list(range(20050,20100)), \"Allahabad\": list(range(20100,20150)), \"Amritsar\": list(range(20150,20200)), \"Asansol\": list(range(20200,20250)), \"Bengaluru\": list(range(20250,20300)), \"Bhopal\": list(range(20300,20350)), \"Bhubaneswar\": list(range(20350,20400)), \"Chandigarh\": list(range(20400,20450)), \"Chennai\": list(range(20450,20500)), \"Dehradun\": list(range(20500,20550)), \"Delhi\": list(range(20550,20600)), \"Goa\": list(range(20600,20650)), \"Guwahati\": list(range(20650,20700)), \"Howrah\": list(range(20700,20750)), \"Hyderabad\": list(range(20750,20800)), \"Indore\": list(range(20800,20850)), \"Jaipur\": list(range(20850,20900)), \"Jalandhar\": list(range(20900,20950)), \"Kanpur\": list(range(20950,21000)), \"Kolkata\": list(range(21000,21050)), \"Kota\": list(range(21050,21100)), \"Lucknow\": list(range(21100,21150)), \"Ludhiana\": list(range(21150,21200)), \"Mumbai\": list(range(21200,21250)), \"Mysuru\": list(range(21250,21300)), \"Nagpur\": list(range(21300,21350)), \"Nasik\": list(range(21350,21400)), \"New Delhi\": list(range(21400,21450)), \"Pune\": list(range(21450,21500)), \"Rajkot\": list(range(21500,21550)), \"Ranchi\": list(range(21550,21600)), \"Surat\": list(range(21600,21650)), \"Tiruchirapalli\": list(range(21650,21700)), \"Vadodara\": list(range(21700,21750)), \"Varanasi\": list(range(21750,21800)), \"Vijayawada\": list(range(21800,21850))}\n",
    "\n",
    "city_pincode_ranges = {\"Agra\": (282001, 283202),\"Ahmedabad\": (380001, 382480),\"Allahabad\": (211001, 274308),\"Amritsar\":(143001, 143606),\"Asansol\": (713201, 713386),\"Bengaluru\": (560001, 560500),\"Bhopal\": (462001, 464993),\"Bhubaneswar\": (751001, 754012),\"Chandigarh\": (140001, 160104),\"Chennai\": (600001, 600119),\"Dehradun\": (247656, 249411),\"Delhi\": (110006, 110099),\"Goa\": (403001, 403806),\"Guwahati\": (781001, 782403),\"Howrah\": (711101, 711414),\"Hyderabad\": (500001, 501512),\"Indore\": (452001, 452018),\"Jaipur\": (302001, 302043),\"Jalandhar\": (144001, 144518),\"Kanpur\": (208001, 209402),\"Kolkata\": (700001, 700163),\"Kota\": (324001, 328216),\"Lucknow\": (226001, 226501),\"Ludhiana\": (141001, 141017),\"Mumbai\": (400001, 400104),\"Mysuru\": (570001, 571617),\"Nagpur\": (440001, 440037),\"Nasik\": (422001, 422606),\"New Delhi\": (110001, 110097),\"Pune\": (411001, 411068),\"Rajkot\": (360001, 363670),\"Ranchi\": (834001, 835325),\"Surat\": (394101, 395023),\"Tiruchirapalli\": (608901, 639115),\"Vadodara\": (390001, 392310),\"Varanasi\": (221001, 232120),\"Vijayawada\": (509132, 521457)}\n",
    "\n",
    "# -----------------------\n",
    "# Product Category Popularity & Customer Segmentation\n",
    "# -----------------------\n",
    "SEGMENTATION_WEIGHT = {\n",
    "    \"Premium\": 1.0,\n",
    "    \"Regular\": 1.5,\n",
    "    \"New\": 0.5,\n",
    "    \"Inactive\": 0.2\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# Global Inventory Dictionary\n",
    "# -----------------------\n",
    "inventory_dict = {}\n",
    "products_dict = {}\n",
    "\n",
    "# -----------------------\n",
    "# Helper Function to Determine Season\n",
    "# -----------------------\n",
    "def get_season(current_date):\n",
    "    m = current_date.month\n",
    "    if m in (12, 1, 2): return 'winter'\n",
    "    if m in (3, 4, 5): return 'spring'\n",
    "    if m in (6, 7, 8): return 'summer'\n",
    "    return 'autumn'\n",
    "\n",
    "# -----------------------\n",
    "# Customer Segmentation\n",
    "# -----------------------\n",
    "def update_segmentation(customer, current_date):\n",
    "    reg = customer['registration_date']\n",
    "    last = customer.get('last_order_date', reg)\n",
    "    total = customer.get('total_orders', 0)\n",
    "    days_since_reg = (current_date - reg).days\n",
    "    days_since_last = (current_date - last).days if last else None\n",
    "    if days_since_reg <= 60:\n",
    "        seg = \"New\"\n",
    "    elif days_since_last is not None and days_since_last > 120:\n",
    "        seg = \"Inactive\"\n",
    "    elif total >= 60:\n",
    "        seg = \"Premium\"\n",
    "    else:\n",
    "        seg = \"Regular\"\n",
    "    customer['segmentation'] = seg\n",
    "    return customer\n",
    "\n",
    "# -----------------------\n",
    "# Time & Product Selection\n",
    "# -----------------------\n",
    "def weighted_time_in_day(target_date):\n",
    "    slots = [((0,0),(7,0),5),((7,0),(10,0),10),((10,0),(12,0),15),\n",
    "             ((12,0),(14,0),10),((14,0),(18,0),20),((18,0),(21,0),30),((21,0),(23,59),10)]\n",
    "    chosen = random.choices(slots, weights=[s[2] for s in slots], k=1)[0]\n",
    "    start = datetime.combine(target_date, time(*chosen[0]))\n",
    "    end   = datetime.combine(target_date, time(*chosen[1]))\n",
    "    sec = max(1, int((end-start).total_seconds()))\n",
    "    return start + timedelta(seconds=random.randint(0,sec))\n",
    "\n",
    "def select_product_for_order(products):\n",
    "    avail = [p for p in products if inventory_dict.get(p['product_id'],{}).get('current_stock',0)>0]\n",
    "    if not avail: return None\n",
    "    weights = {\n",
    "        'Grocery & Staples':25,'Dairy & Breakfast':18,'Fruits & Vegetables':15,\n",
    "        'Snacks & Munchies':10,'Cold Drinks & Juices':6,'Instant & Frozen Food':9,\n",
    "        'Household Care':5,'Personal Care':3,'Baby Care':2,'Pet Care':1,'Pharmacy':6\n",
    "    }\n",
    "    return random.choices(avail, weights=[weights.get(p['category'],1) for p in avail], k=1)[0]\n",
    "\n",
    "# -----------------------\n",
    "# Growth & Orders Target\n",
    "# -----------------------\n",
    "growth_factors = {}\n",
    "def get_growth_factor(year, day_type):\n",
    "    if year not in growth_factors:\n",
    "        if year == 2022:\n",
    "            growth_factors[2022] = (1.0,1.0)\n",
    "        else:\n",
    "            prev = year-1\n",
    "            _ = get_growth_factor(prev,'weekday')\n",
    "            _ = get_growth_factor(prev,'weekend')\n",
    "            w = min(growth_factors[prev][0]*random.uniform(1.23,1.28),10)\n",
    "            e = min(growth_factors[prev][1]*random.uniform(1.25,1.33),10)\n",
    "            growth_factors[year]=(w,e)\n",
    "    return growth_factors[year][0] if day_type=='weekday' else growth_factors[year][1]\n",
    "\n",
    "def get_orders_target_for_date(target_date):\n",
    "    dt = target_date.weekday()\n",
    "    dt_type = 'weekday' if dt<5 else 'weekend'\n",
    "    base = random.randint(160,200) if dt_type=='weekday' else random.randint(185,245)\n",
    "    fac = get_growth_factor(target_date.year,dt_type)\n",
    "    raw = base*fac\n",
    "    days = calendar.monthrange(target_date.year,target_date.month)[1]\n",
    "    mf = 1.0-0.3*((target_date.day-1)/(days-1))\n",
    "    return max(1,int(round(raw*mf)))\n",
    "\n",
    "# -----------------------\n",
    "# Dynamic Pricing\n",
    "# -----------------------\n",
    "def compute_dynamic_price(product, available_stock, current_date, days_since_replenishment=None):\n",
    "    mrp0 = product['mrp']\n",
    "    max_s = product['max_stock_level'] or 1\n",
    "    ratio = available_stock / max_s\n",
    "    if ratio < 0.2:\n",
    "        price = mrp0 * random.uniform(1.10, 1.25)\n",
    "    elif ratio < 0.4:\n",
    "        price = mrp0 * random.uniform(1.05, 1.10)\n",
    "    elif ratio > 0.8:\n",
    "        price = mrp0 * random.uniform(0.75, 0.90)\n",
    "    elif ratio > 0.6:\n",
    "        price = mrp0 * random.uniform(0.90, 0.95)\n",
    "    else:\n",
    "        price = mrp0 * random.uniform(0.97, 1.03)\n",
    "    if days_since_replenishment is not None and days_since_replenishment >= 0.8 * product['shelf_life_days']:\n",
    "        price *= (1 - random.uniform(0.12, 0.20))\n",
    "    return round(price)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Inventory Functions\n",
    "# -----------------------\n",
    "def initialize_inventory(products_df, start_date):\n",
    "    inv_records = []\n",
    "    d0 = datetime.strptime(DEFAULT_START_DATE, '%Y-%m-%d').date()\n",
    "    for _, row in products_df.iterrows():\n",
    "        pid = row['product_id']\n",
    "        init_stock = 0 if start_date == DEFAULT_START_DATE else random.randint(row['min_stock_level'], row['max_stock_level'])\n",
    "        base_cost = row['base_purchasing_cost']\n",
    "        purchasing_cost_today = base_cost\n",
    "        price_today = compute_dynamic_price(row, init_stock, d0, days_since_replenishment=0)\n",
    "        inventory_dict[pid] = {\n",
    "            'current_stock': init_stock,\n",
    "            'min_stock_level': row['min_stock_level'],\n",
    "            'max_stock_level': row['max_stock_level'],\n",
    "            'last_replenishment_date': d0,\n",
    "            'new_stock': init_stock,\n",
    "            'damaged_stock': 0,\n",
    "            'latest_price': price_today,\n",
    "            'purchasing_cost': purchasing_cost_today,\n",
    "            'prev_day_end_stock': init_stock,\n",
    "            'sold_stock': 0\n",
    "        }\n",
    "        inv_records.append({\n",
    "            'product_id': pid,\n",
    "            'date': d0,\n",
    "            'mrp': row['mrp'],\n",
    "            'price': price_today,\n",
    "            'purchasing_cost': purchasing_cost_today,\n",
    "            'Selling Cost': 0.0,\n",
    "            'profit': 0.0,\n",
    "            'new_stock': init_stock,\n",
    "            'start_available_stock': init_stock,\n",
    "            'sold_stock': 0,\n",
    "            'end_available_stock': init_stock,\n",
    "            'damaged_stock': 0\n",
    "        })\n",
    "    return pd.DataFrame(inv_records)\n",
    "\n",
    "def update_inventory_record_for_day(current_date, products_dict, inventory_dict):\n",
    "    records = []\n",
    "    for pid, inv in inventory_dict.items():\n",
    "        prod = products_dict[pid]\n",
    "        days_since_repl = (current_date - inv['last_replenishment_date']).days\n",
    "        # Spoilage\n",
    "        damaged = 0\n",
    "        if days_since_repl >= prod['shelf_life_days']:\n",
    "            damaged = inv['current_stock']\n",
    "            inv['current_stock'] = 0\n",
    "        inv['damaged_stock'] = damaged\n",
    "        # Restock\n",
    "        new_stock_qty = 0\n",
    "        if inv['current_stock'] < prod['min_stock_level']:\n",
    "            target = prod['max_stock_level']\n",
    "            replen_qty = (target - inv['current_stock']) + random.randint(-3, 3)\n",
    "            replen_qty = max(replen_qty, 0)\n",
    "            if replen_qty > 0:\n",
    "                replenishment_quantity = replen_qty\n",
    "                new_stock_qty = replenishment_quantity\n",
    "                inv['current_stock'] += replen_qty\n",
    "                inv['last_replenishment_date'] = current_date\n",
    "        inv['new_stock'] = new_stock_qty\n",
    "        # Start available\n",
    "        if 'prev_day_end_stock' in inv:\n",
    "            start_available = inv['prev_day_end_stock'] + new_stock_qty\n",
    "        else:\n",
    "            start_available = inv['current_stock'] + inv['sold_stock'] + damaged - new_stock_qty\n",
    "        inv['start_available_stock'] = start_available\n",
    "        # Sold\n",
    "        sold = inv['sold_stock']\n",
    "        # End available\n",
    "        end_stock = inv['current_stock']\n",
    "        inv['end_available_stock'] = end_stock\n",
    "        # Purchasing cost (season + wiggle)\n",
    "        base_cost = prod['base_purchasing_cost']\n",
    "        season = get_season(current_date)\n",
    "        if season == 'summer':\n",
    "            season_mult = random.uniform(1.03, 1.10)\n",
    "        elif season == 'winter':\n",
    "            season_mult = random.uniform(0.90, 0.98)\n",
    "        else:\n",
    "            season_mult = random.uniform(0.97, 1.03)\n",
    "        wiggle_pct = random.uniform(-0.03, 0.03)\n",
    "        purchase_cost = round(base_cost * season_mult * (1 + wiggle_pct), 2)\n",
    "        inv['purchasing_cost'] = purchase_cost\n",
    "        # Raw dynamic price\n",
    "        raw_price = compute_dynamic_price(prod, start_available, current_date, days_since_repl)\n",
    "        # Bump MRP if raw_price > static MRP\n",
    "        today_mrp = prod['mrp']\n",
    "        if raw_price > today_mrp:\n",
    "            today_mrp = raw_price\n",
    "        # Selling cost per unit (5-15% of purchase)\n",
    "        selling_cost = max(purchase_cost * random.uniform(0.06, 0.10),3)\n",
    "        inv['selling_cost_per_unit'] = selling_cost\n",
    "        # Final price enforce floor and cap\n",
    "        floor_price = purchase_cost + selling_cost\n",
    "        final_price = max(raw_price, floor_price)\n",
    "        final_price = min(final_price, today_mrp)\n",
    "        inv['price'] = round(final_price, 2)\n",
    "        # Profit per unit\n",
    "        unit_profit = round(final_price - (purchase_cost + selling_cost), 2)\n",
    "        # Build record in desired column order\n",
    "        row = {\n",
    "            'product_id': pid,\n",
    "            'date': current_date,\n",
    "            'mrp': today_mrp,\n",
    "            'price': inv['price'],\n",
    "            'purchasing_cost': purchase_cost,\n",
    "            'Selling Cost': selling_cost,\n",
    "            'profit': unit_profit,\n",
    "            'new_stock': new_stock_qty,\n",
    "            'start_available_stock': start_available,\n",
    "            'sold_stock': sold,\n",
    "            'end_available_stock': end_stock,  # <-- changed from 'end_available_stock'\n",
    "            'damaged_stock': damaged\n",
    "        }\n",
    "        records.append(row)\n",
    "        # Store end-of-day\n",
    "        inv['prev_day_end_stock'] = end_stock\n",
    "        inv['sold_stock'] = 0\n",
    "    return records\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Order Generation Helpers\n",
    "# -----------------------\n",
    "\n",
    "def get_new_date_range(path, default):\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df=pd.read_csv(path,parse_dates=['order_date'])\n",
    "        except:\n",
    "            df=pd.DataFrame()\n",
    "        if not df.empty:\n",
    "            last=df['order_date'].max().date()\n",
    "            start=last+timedelta(days=1)\n",
    "        else:\n",
    "            start=datetime.strptime(default,'%Y-%m-%d').date()\n",
    "    else:\n",
    "        start=datetime.strptime(default,'%Y-%m-%d').date()\n",
    "    return start, date.today()\n",
    "\n",
    "\n",
    "def generate_orders_for_day(target_date, eligible_customers, products, customers_dict,\n",
    "                            oid_start, fid_start, orders_target):\n",
    "    orders = []\n",
    "    items_list = []\n",
    "    perf = []\n",
    "    feedback = []\n",
    "\n",
    "    order_id = oid_start\n",
    "    fid = fid_start\n",
    "    seg_w = [SEGMENTATION_WEIGHT.get(c.get('segmentation','Regular'),1) for c in eligible_customers]\n",
    "    gen = 0\n",
    "\n",
    "    while gen < orders_target:\n",
    "        cust = random.choices(eligible_customers, weights=seg_w, k=1)[0]\n",
    "        cid = cust['customer_id']\n",
    "        dp = city_delivery_partners.get(cust['city'])\n",
    "        od = weighted_time_in_day(target_date)\n",
    "        if od.date() < cust['registration_date']:\n",
    "            od = datetime.combine(cust['registration_date'], od.time())\n",
    "        prom = od + timedelta(minutes=random.randint(8,10))\n",
    "        delay = random.randint(5,10) if cust['city'] in [\"Mumbai\",\"Delhi\"] else 0\n",
    "\n",
    "        # Build items\n",
    "        num = random.randint(1,3)\n",
    "        items = []\n",
    "        total = 0.0\n",
    "        canceled = False\n",
    "        stock_canceled = False\n",
    "        for _ in range(num):\n",
    "            prod = select_product_for_order(products)\n",
    "            if prod is None:\n",
    "                canceled = True\n",
    "                stock_canceled = True\n",
    "                break\n",
    "            pid = prod['product_id']\n",
    "            cs = inventory_dict[pid]['current_stock']\n",
    "            if cs < 1:\n",
    "                canceled = True\n",
    "                stock_canceled = True\n",
    "                break\n",
    "            qty = random.randint(1, min(3, cs))\n",
    "            up = inventory_dict[pid]['latest_price']\n",
    "            items.append({\n",
    "                'order_id': order_id,\n",
    "                'product_id': pid,\n",
    "                'quantity': qty,\n",
    "                'unit_price': up,\n",
    "                'total_price': round(up * qty, 2)\n",
    "            })\n",
    "            total += up * qty\n",
    "            inventory_dict[pid]['current_stock'] -= qty\n",
    "            inventory_dict[pid].setdefault('sold_stock', 0)\n",
    "            inventory_dict[pid]['sold_stock'] += qty\n",
    "\n",
    "        # Random cancellation\n",
    "        if random.random() < 0.04:\n",
    "            canceled = True\n",
    "\n",
    "        # Roll back and reset on cancellation\n",
    "        if canceled:\n",
    "            for it in items:\n",
    "                pid = it['product_id']\n",
    "                inventory_dict[pid]['current_stock'] += it['quantity']\n",
    "                inventory_dict[pid]['sold_stock'] -= it['quantity']\n",
    "            total = 0.0  # <<< Reset total when canceled\n",
    "\n",
    "        # Determine final status and delivery times\n",
    "        if canceled:\n",
    "            status = 'Cancelled'\n",
    "            dstatus = 'Cancelled'\n",
    "            # Distinguish stock vs. user/random cancellations:\n",
    "            if stock_canceled:\n",
    "                reason = \"Product Unavailable\"\n",
    "            else:\n",
    "                reason = random.choices(\n",
    "                    ['Customer Cancellation','Payment Issue','Changed Mind','Found Cheaper Alternative','Price Issue','Stock Issue'],weights=[17,18,13,15,22,9]\n",
    "                )[0]\n",
    "            ad = None\n",
    "        else:\n",
    "            status = 'Completed'\n",
    "            r = random.random()\n",
    "            if r < 0.87:\n",
    "                ad = od + timedelta(minutes=random.randint(6,10) + delay)\n",
    "                dstatus = 'On Time'\n",
    "                reason = None\n",
    "            elif r < 0.93:\n",
    "                ad = od + timedelta(minutes=random.randint(11,22) + delay)\n",
    "                dstatus = 'Slightly Delayed'\n",
    "                reason = random.choices(\n",
    "                    [\"Traffic\", \"Stock Issue\", \"Weather\", \"Technical Issue\"],\n",
    "                    weights=[33,37,25,15]\n",
    "                )[0]\n",
    "            else:\n",
    "                ad = od + timedelta(minutes=random.randint(22,40) + delay)\n",
    "                dstatus = 'Significantly Delayed'\n",
    "                reason = random.choices(\n",
    "                    [\"Traffic\", \"Stock Issue\", \"Weather\", \"Technical Issue\"],\n",
    "                    weights=[39,26,22,15]\n",
    "                )[0]\n",
    "        sp = store_ids.get(cust['city']) \n",
    "        order_rec = {\n",
    "            'order_id': order_id,\n",
    "            'customer_id': cid,\n",
    "            'order_date': od,\n",
    "            'promised_delivery_time': prom,\n",
    "            'actual_delivery_time': ad,\n",
    "            'delivery_status': dstatus,\n",
    "            'order_total': round(total, 2),\n",
    "            'payment_method': random.choices(\n",
    "                ['UPI','Card','COD','Wallet'], weights=[70,5,10,15]\n",
    "            )[0],\n",
    "            'delivery_partner_id': random.choice(dp),\n",
    "            'store_id': random.choice(sp),\n",
    "            'delay_reason': reason,\n",
    "            'order_status': status\n",
    "        }\n",
    "\n",
    "        # 4) Always log the order header\n",
    "        orders.append(order_rec)\n",
    "\n",
    "        # 5) Always log all attempted items\n",
    "        items_list.extend(items)\n",
    "\n",
    "        # 6) Log performance (ETA/distance) even for cancelled\n",
    "        perf.append({\n",
    "            'order_id': order_id,\n",
    "            'delivery_partner_id': random.choice(dp),\n",
    "            'promised_time': prom,\n",
    "            'actual_time': ad,\n",
    "            'delivery_time_minutes': round((ad - od).total_seconds() / 60, 2) if ad else None,\n",
    "            'distance_km': round(random.uniform(0.5,5), 2),\n",
    "            'delivery_status': dstatus,\n",
    "            'reasons_if_delayed': reason\n",
    "        })\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 7) **FEEDBACK**: pull from realistic_feedback_df\n",
    "        # -------------------------------------------------------\n",
    "        if status == 'Cancelled':\n",
    "            fr = realistic_feedback_df[\n",
    "                (realistic_feedback_df['order_status'] == 'Cancelled') &\n",
    "                (realistic_feedback_df['feedback_category'].isin(cancel_reasons))\n",
    "            ]\n",
    "        else:\n",
    "            if dstatus == 'On Time':\n",
    "                fr = realistic_feedback_df[\n",
    "                    (realistic_feedback_df['order_status'] == 'Completed') &\n",
    "                    (realistic_feedback_df['sentiment'] == 'Positive')\n",
    "                ]\n",
    "            elif dstatus == 'Slightly Delayed':\n",
    "                fr = realistic_feedback_df[\n",
    "                    (realistic_feedback_df['order_status'] == 'Completed') &\n",
    "                    (realistic_feedback_df['feedback_category'] == 'Delivery Concern')\n",
    "                ]\n",
    "            else:  # Fully late or other negative experiences\n",
    "                fr = realistic_feedback_df[\n",
    "                    (realistic_feedback_df['order_status'] == 'Completed') &\n",
    "                    (realistic_feedback_df['feedback_category'] == 'Slow Delivery')\n",
    "                ]\n",
    "\n",
    "        if not fr.empty:\n",
    "            row = fr.sample().iloc[0]\n",
    "            fb = {\n",
    "                'feedback_id': fid,\n",
    "                'order_id': order_id,\n",
    "                'customer_id': cid,\n",
    "                'rating': row['rating'],\n",
    "                'feedback_text': row['feedback_text'],\n",
    "                'feedback_category': row['feedback_category'],\n",
    "                'sentiment': row['sentiment'],\n",
    "                'feedback_date': (ad if ad else od) + timedelta(minutes=random.randint(10,60)),\n",
    "                'order_status': status\n",
    "            }\n",
    "        else:\n",
    "            if status == 'Cancelled':\n",
    "                fb = {\n",
    "                    'feedback_id': fid,\n",
    "                    'order_id': order_id,\n",
    "                    'customer_id': cid,\n",
    "                    'rating': 1,\n",
    "                    'feedback_text': 'Order cancelled',\n",
    "                    'feedback_category': 'Cancellation',\n",
    "                    'sentiment': 'Negative',\n",
    "                    'feedback_date': od + timedelta(minutes=random.randint(10,60)),\n",
    "                    'order_status': status\n",
    "                }\n",
    "            else:\n",
    "                fallback_sent = 'Positive' if dstatus == 'On Time' else 'Neutral'\n",
    "                fb = {\n",
    "                    'feedback_id': fid,\n",
    "                    'order_id': order_id,\n",
    "                    'customer_id': cid,\n",
    "                    'rating': 5 if dstatus == 'On Time' else 3,\n",
    "                    'feedback_text': 'All good' if dstatus == 'On Time' else 'Delivery was late',\n",
    "                    'feedback_category': 'Fast Delivery' if dstatus == 'On Time' else 'Slow Delivery',\n",
    "                    'sentiment': fallback_sent,\n",
    "                    'feedback_date': ad + timedelta(minutes=random.randint(10,60)),\n",
    "                    'order_status': status\n",
    "                }\n",
    "\n",
    "        feedback.append(fb)\n",
    "        fid += 1\n",
    "        # -------------------------------------------------------\n",
    "\n",
    "        # 8) Only update customer stats for completed orders\n",
    "        if not canceled:\n",
    "            old_tot = cust.get('total_orders', 0)\n",
    "            old_avg = cust.get('avg_order_value', 0)\n",
    "            new_tot = old_tot + 1\n",
    "            new_avg = round(((old_avg * old_tot) + total) / new_tot, 2) if new_tot else total\n",
    "            cust['total_orders']    = new_tot\n",
    "            cust['avg_order_value'] = new_avg\n",
    "            cust['last_order_date'] = od.date()\n",
    "            customers_dict[cid]     = update_segmentation(cust, target_date)\n",
    "\n",
    "        # 9) Advance IDs and counters\n",
    "        order_id += 1\n",
    "        if not canceled:\n",
    "            gen += 1\n",
    "\n",
    "    return orders, items_list, perf, feedback, order_id, fid\n",
    "\n",
    "\n",
    "def generate_first_order_for_customer(customer, products, customers_dict, order_id, fid, target_date):\n",
    "    cid = customer['customer_id']\n",
    "    dp = city_delivery_partners.get(customer['city'])\n",
    "    sp = store_ids.get(customer['city'])\n",
    "    od = weighted_time_in_day(target_date)\n",
    "    if od.date() != customer['registration_date']:\n",
    "        od = datetime.combine(customer['registration_date'], od.time())\n",
    "    prom = od + timedelta(minutes=random.randint(8,10))\n",
    "    delay = random.randint(5,10) if customer['city'] in [\"Mumbai\",\"Delhi\"] else 0\n",
    "\n",
    "    num = random.randint(1,3)\n",
    "    items = []\n",
    "    total = 0.0\n",
    "    canceled = False\n",
    "    for _ in range(num):\n",
    "        prod = select_product_for_order(products)\n",
    "        if prod is None:\n",
    "            canceled = True\n",
    "            break\n",
    "        pid = prod['product_id']\n",
    "        cs = inventory_dict[pid]['current_stock']\n",
    "        if cs < 1:\n",
    "            canceled = True\n",
    "            break\n",
    "        qty = random.randint(1, min(3, cs))\n",
    "        up = inventory_dict[pid]['latest_price']\n",
    "        items.append({'order_id':order_id,'product_id':pid,'quantity':qty,'unit_price':up,'total_price':round(up*qty,2)})\n",
    "        total += up * qty\n",
    "        inventory_dict[pid]['current_stock'] -= qty\n",
    "        inventory_dict[pid].setdefault('sold_stock',0)\n",
    "        inventory_dict[pid]['sold_stock'] += qty\n",
    "\n",
    "    if random.random() < 0.04:\n",
    "        canceled = True\n",
    "\n",
    "    if canceled:\n",
    "        for it in items:\n",
    "            pid = it['product_id']\n",
    "            inventory_dict[pid]['current_stock'] += it['quantity']\n",
    "            inventory_dict[pid]['sold_stock'] -= it['quantity']\n",
    "        total = 0.0  # reset total on cancellation\n",
    "\n",
    "    if canceled:\n",
    "        status = 'Cancelled'\n",
    "        dstatus = 'Cancelled'\n",
    "        reason = \"Product Unavailable\" if canceled else random.choice(\n",
    "            [\"Customer Cancellation\",\"Payment Issue\",\"Changed Mind\",\"Found Cheaper Alternative\"]\n",
    "        )\n",
    "        ad = None\n",
    "    else:\n",
    "        status = 'Completed'\n",
    "        r = random.random()\n",
    "        if r < 0.87:\n",
    "            ad = od + timedelta(minutes=random.randint(6,10)+delay)\n",
    "            dstatus = 'On Time'\n",
    "            reason = None\n",
    "        elif r < 0.93:\n",
    "            ad = od + timedelta(minutes=random.randint(11,22)+delay)\n",
    "            dstatus = 'Slightly Delayed'\n",
    "            reason = random.choices(\n",
    "                [\"Traffic\",\"Stock Issue\",\"Weather\",\"Technical Issue\"],\n",
    "                weights=[30,30,25,15]\n",
    "            )[0]\n",
    "        else:\n",
    "            ad = od + timedelta(minutes=random.randint(22,40)+delay)\n",
    "            dstatus = 'Significantly Delayed'\n",
    "            reason = random.choices(\n",
    "                [\"Traffic\",\"Stock Issue\",\"Weather\",\"Technical Issue\"],\n",
    "                weights=[30,30,25,15]\n",
    "            )[0]\n",
    "   \n",
    "    order_rec = {\n",
    "        'order_id': order_id,\n",
    "        'customer_id': cid,\n",
    "        'order_date': od,\n",
    "        'promised_delivery_time': prom,\n",
    "        'actual_delivery_time': ad,\n",
    "        'delivery_status': dstatus,\n",
    "        'order_total': round(total,2),\n",
    "        'payment_method': random.choices(['UPI','Card','COD','Wallet'],[70,5,10,15])[0],\n",
    "        'delivery_partner_id': random.choice(dp),\n",
    "        'store_id': random.choice(sp),\n",
    "        'delay_reason': reason,\n",
    "        'order_status': status\n",
    "    }\n",
    "    perf = {\n",
    "        'order_id': order_id,\n",
    "        'delivery_partner_id': random.choice(dp),\n",
    "        'promised_time': prom,\n",
    "        'actual_time': ad,\n",
    "        'delivery_time_minutes': round((ad-od).total_seconds()/60,2) if ad else None,\n",
    "        'distance_km': round(random.uniform(0.5,5),2),\n",
    "        'delivery_status': dstatus,\n",
    "        'reasons_if_delayed': reason\n",
    "    }\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Feedback for first‐order: same logic as generate_orders_for_day\n",
    "    # -------------------------------------------------------\n",
    "    if status == 'Cancelled':\n",
    "        fr = realistic_feedback_df[\n",
    "            (realistic_feedback_df['order_status'] == 'Cancelled') &\n",
    "            (realistic_feedback_df['feedback_category'].isin(cancel_reasons))\n",
    "        ]\n",
    "    else:\n",
    "        if dstatus == 'On Time':\n",
    "            fr = realistic_feedback_df[\n",
    "                (realistic_feedback_df['order_status'] == 'Completed') &\n",
    "                (realistic_feedback_df['sentiment'] == 'Positive')\n",
    "            ]\n",
    "        else:\n",
    "            fr = realistic_feedback_df[\n",
    "                (realistic_feedback_df['order_status'] == 'Completed') &\n",
    "                (realistic_feedback_df['feedback_category'] == 'Slow Delivery')\n",
    "            ]\n",
    "\n",
    "    if not fr.empty:\n",
    "        row = fr.sample().iloc[0]\n",
    "        fb = {\n",
    "            'feedback_id': fid,\n",
    "            'order_id': order_id,\n",
    "            'customer_id': cid,\n",
    "            'rating': row['rating'],\n",
    "            'feedback_text': row['feedback_text'],\n",
    "            'feedback_category': row['feedback_category'],\n",
    "            'sentiment': row['sentiment'],\n",
    "            'feedback_date': (ad if ad else od) + timedelta(minutes=random.randint(10,60)),\n",
    "            'order_status': status\n",
    "        }\n",
    "    else:\n",
    "        if status == 'Cancelled':\n",
    "            fb = {\n",
    "                'feedback_id': fid,\n",
    "                'order_id': order_id,\n",
    "                'customer_id': cid,\n",
    "                'rating': 1,\n",
    "                'feedback_text': 'Order cancelled',\n",
    "                'feedback_category': 'Cancellation',\n",
    "                'sentiment': 'Negative',\n",
    "                'feedback_date': od + timedelta(minutes=random.randint(10,60)),\n",
    "                'order_status': status\n",
    "            }\n",
    "        else:\n",
    "            fallback_sent = 'Positive' if dstatus == 'On Time' else 'Neutral'\n",
    "            fb = {\n",
    "                'feedback_id': fid,\n",
    "                'order_id': order_id,\n",
    "                'customer_id': cid,\n",
    "                'rating': 5 if dstatus == 'On Time' else 3,\n",
    "                'feedback_text': 'All good' if dstatus == 'On Time' else 'Delivery was late',\n",
    "                'feedback_category': 'Fast Delivery' if dstatus == 'On Time' else 'Slow Delivery',\n",
    "                'sentiment': fallback_sent,\n",
    "                'feedback_date': ad + timedelta(minutes=random.randint(10,60)),\n",
    "                'order_status': status\n",
    "            }\n",
    "\n",
    "    fid += 1\n",
    "    # -------------------------------------------------------\n",
    "\n",
    "    # Only update stats for completed\n",
    "    if not canceled:\n",
    "        old_tot = customer.get('total_orders', 0)\n",
    "        old_avg = customer.get('avg_order_value', 0)\n",
    "        new_tot = old_tot + 1\n",
    "        new_avg = round(((old_avg * old_tot) + total) / new_tot, 2) if new_tot else total\n",
    "        customer['total_orders']    = new_tot\n",
    "        customer['avg_order_value'] = new_avg\n",
    "        customer['last_order_date'] = od.date()\n",
    "        customers_dict[cid] = update_segmentation(customer, target_date)\n",
    "\n",
    "    return order_rec, items, perf, fb, order_id+1, fid+1\n",
    "\n",
    "# -----------------------\n",
    "# New Customer Simulation & Daily Loop\n",
    "# -----------------------\n",
    "def simulate_new_customers_for_day(current_date, num_new_customers, next_cid, emails, phones):\n",
    "    new_cust=[]\n",
    "    for _ in range(num_new_customers):\n",
    "        raw = fake.address().replace(\"\\n\", \", \")\n",
    "        # Split into components\n",
    "        parts = [p.strip() for p in raw.split(\",\") if p.strip()]\n",
    "        # street is first part, area is second if exists, else fallback\n",
    "        street = fake.street_name()\n",
    "        area = parts[1] if len(parts) > 1 else fake.street_name()\n",
    "        house_num = fake.building_number()\n",
    "        city = random.choices(CITY_LIST, weights=CITY_WEIGHTS)[0]\n",
    "        pincode_low, pincode_high = city_pincode_ranges[city]\n",
    "        pin = random.randint(pincode_low, pincode_high)\n",
    "        address = f\"{house_num} {street} , {area}\"\n",
    "        name = fake.name()\n",
    "\n",
    "        # Email based on name\n",
    "        local = name.lower().replace(\" \", \".\")\n",
    "        domain = random.choice([\"gmail.com\", \"yahoo.com\", \"outlook.com\"])\n",
    "        email = f\"{local}{random.randint(1,999)}@{domain}\"\n",
    "\n",
    "        # Indian mobile number +91 and 10 digits starting 6–9\n",
    "        phone = f\"+91{random.randint(6000000000, 9999999999)}\"\n",
    "        \n",
    "        cust={'customer_id':next_cid,'customer_name':name,'email':email,'phone':phone,'address':address,'area':city,'city':city,'pincode':pin,'registration_date':current_date,'total_orders':0,'avg_order_value':0,'last_order_date':current_date,'segmentation':'New'}\n",
    "        new_cust.append(cust); next_cid+=1\n",
    "    return new_cust, next_cid\n",
    "\n",
    "\n",
    "def generate_new_daily_orders(new_start_date, new_end_date):\n",
    "    # --- LOAD/INIT CUSTOMERS & PRODUCTS ---\n",
    "    try:\n",
    "        cust_df = pd.read_csv(STATIC_CUSTOMERS_CSV, parse_dates=['registration_date', 'last_order_date'])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading {STATIC_CUSTOMERS_CSV}: {e}\")\n",
    "        return {}\n",
    "\n",
    "    cust_df['registration_date'] = cust_df['registration_date'].dt.date\n",
    "    cust_df['last_order_date']   = cust_df['last_order_date'].dt.date\n",
    "    customers_dict_local = {\n",
    "        row['customer_id']: row.to_dict()\n",
    "        for _, row in cust_df.iterrows()\n",
    "    }\n",
    "    global customers_dict\n",
    "    customers_dict = customers_dict_local\n",
    "\n",
    "    next_customer_id = max(customers_dict.keys()) + 1\n",
    "    existing_emails = {c['email'] for c in customers_dict.values()}\n",
    "    existing_phones = {c['phone'] for c in customers_dict.values()}\n",
    "\n",
    "    if os.path.exists(STATIC_PRODUCTS_CSV) and os.path.getsize(STATIC_PRODUCTS_CSV) > 0:\n",
    "        prod_df = pd.read_csv(STATIC_PRODUCTS_CSV)\n",
    "    else:\n",
    "        prod_df = generate_static_products()\n",
    "        prod_df.to_csv(STATIC_PRODUCTS_CSV, index=False)\n",
    "    products = prod_df.to_dict('records')\n",
    "    global products_dict\n",
    "    products_dict = {row['product_id']: row for row in products}\n",
    "\n",
    "    if os.path.exists(ORDERS_CSV) and os.path.getsize(ORDERS_CSV) > 0:\n",
    "        try:\n",
    "            old_o = pd.read_csv(ORDERS_CSV)\n",
    "            order_id_counter = int(old_o['order_id'].max()) + 1\n",
    "        except:\n",
    "            order_id_counter = 20000\n",
    "    else:\n",
    "        order_id_counter = 20000\n",
    "\n",
    "    if os.path.exists(CUSTOMER_FEEDBACK_CSV) and os.path.getsize(CUSTOMER_FEEDBACK_CSV) > 0:\n",
    "        try:\n",
    "            old_f = pd.read_csv(CUSTOMER_FEEDBACK_CSV)\n",
    "            feedback_id_counter = int(old_f['feedback_id'].max()) + 1\n",
    "        except:\n",
    "            feedback_id_counter = 1\n",
    "    else:\n",
    "        feedback_id_counter = 1\n",
    "\n",
    "    all_orders = []\n",
    "    all_items = []\n",
    "    all_perf = []\n",
    "    all_feedback = []\n",
    "    inventory_records_list = []\n",
    "\n",
    "    # --- INITIAL INVENTORY LOAD ---\n",
    "    if not os.path.exists(INVENTORY_CSV) or os.path.getsize(INVENTORY_CSV) == 0:\n",
    "        inv_df = initialize_inventory(prod_df, new_start_date)\n",
    "        inventory_records_list.extend(inv_df.to_dict('records'))\n",
    "    else:\n",
    "        inv_df = pd.read_csv(INVENTORY_CSV)\n",
    "        inv_df['date'] = pd.to_datetime(inv_df['date']).dt.date\n",
    "        last_records = (\n",
    "            inv_df\n",
    "            .sort_values('date')\n",
    "            .groupby('product_id')\n",
    "            .last()\n",
    "            .reset_index()\n",
    "        )\n",
    "        for _, row in last_records.iterrows():\n",
    "            pid = row['product_id']\n",
    "            inventory_dict[pid] = {\n",
    "                'current_stock':       row['end_available_stock'],\n",
    "                'last_replenishment_date': row['date'],\n",
    "                'new_stock_arrival':   row['new_stock'],\n",
    "                'damaged_stock':       row['damaged_stock'],\n",
    "                'latest_price':        row['price'],\n",
    "                'purchase_cost':       row['purchasing_cost'],\n",
    "                'stock_last_change_date': row['date'],\n",
    "                'sold_stock':          0\n",
    "            }\n",
    "\n",
    "    # Seed one day before start so first loop can snapshot previous day\n",
    "    prev_date = new_start_date - timedelta(days=1)\n",
    "    # There is no update_inventory_daily function; use update_inventory_record_for_day instead\n",
    "\n",
    "    inventory_records_list.extend(update_inventory_record_for_day(prev_date, products_dict, inventory_dict))\n",
    "\n",
    "    # --- MAIN DAILY Loop ---\n",
    "    cutoff_date = date(2026, 2, 21)\n",
    "    current_date = new_start_date\n",
    "\n",
    "    while current_date <= new_end_date:\n",
    "        # 1) Simulate new customers if past cutoff…\n",
    "        if current_date >= cutoff_date:\n",
    "            new_cs, next_customer_id = simulate_new_customers_for_day(\n",
    "                current_date,\n",
    "                random.randint(5, 15),\n",
    "                next_customer_id,\n",
    "                existing_emails,\n",
    "                existing_phones\n",
    "            )\n",
    "            for cust in new_cs:\n",
    "                customers_dict[cust['customer_id']] = cust\n",
    "\n",
    "        # 2) First orders for brand-new registrations…\n",
    "        eligible = [\n",
    "            c for c in customers_dict.values()\n",
    "            if c['registration_date'] <= current_date\n",
    "        ]\n",
    "        new_today = [\n",
    "            c for c in eligible\n",
    "            if c['registration_date'] == current_date and c.get('total_orders', 0) == 0\n",
    "        ]\n",
    "        for cust in new_today:\n",
    "            order, items, perf, fb, order_id_counter, feedback_id_counter = \\\n",
    "                generate_first_order_for_customer(\n",
    "                    cust, products, customers_dict,\n",
    "                    order_id_counter, feedback_id_counter,\n",
    "                    current_date\n",
    "                )\n",
    "            all_orders.append(order)\n",
    "            all_items.extend(items)\n",
    "            all_perf.append(perf)\n",
    "            all_feedback.append(fb)\n",
    "\n",
    "        # 3) Remaining orders to hit daily target…\n",
    "        target = get_orders_target_for_date(current_date)\n",
    "        remaining = max(0, target - sum(1 for o in all_orders if o['order_date'] == current_date))\n",
    "        if remaining > 0:\n",
    "            orders, items, perf, fb_list, order_id_counter, feedback_id_counter = \\\n",
    "                generate_orders_for_day(\n",
    "                    current_date, eligible, products, customers_dict,\n",
    "                    order_id_counter, feedback_id_counter,\n",
    "                    remaining\n",
    "                )\n",
    "            all_orders.extend(orders)\n",
    "            all_items.extend(items)\n",
    "            all_perf.extend(perf)\n",
    "            all_feedback.extend(fb_list)\n",
    "\n",
    "        # 4) Update segmentation…\n",
    "        for cust in eligible:\n",
    "            customers_dict[cust['customer_id']] = update_segmentation(cust, current_date)\n",
    "\n",
    "        # 5) END-OF-DAY INVENTORY SNAPSHOT\n",
    "        daily_records = update_inventory_record_for_day(current_date, products_dict, inventory_dict)\n",
    "        inventory_records_list.extend(daily_records)\n",
    "\n",
    "        # — YEAR-END STOCK-LEVEL GROWTH —\n",
    "        if current_date.month == 12 and current_date.day == 31:\n",
    "            prod_df = pd.read_csv(STATIC_PRODUCTS_CSV)\n",
    "            for idx, row in prod_df.iterrows():\n",
    "                growth = random.uniform(0.20, 0.25)\n",
    "                prod_df.at[idx, 'max_stock_level'] = int(round(row['max_stock_level'] * (1 + growth)))\n",
    "                prod_df.at[idx, 'min_stock_level'] = int(round(row['min_stock_level'] * (1 + growth)))\n",
    "            prod_df.to_csv(STATIC_PRODUCTS_CSV, index=False)\n",
    "\n",
    "            products = prod_df.to_dict('records')\n",
    "            products_dict.clear()\n",
    "            products_dict.update({p['product_id']: p for p in products})\n",
    "            for pid, inv in inventory_dict.items():\n",
    "                inv['min_stock_level'] = products_dict[pid]['min_stock_level']\n",
    "                inv['max_stock_level'] = products_dict[pid]['max_stock_level']\n",
    "            logging.info(f\"Year-end stock levels bumped for {current_date.year}\")\n",
    "\n",
    "        # 6) Move to next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # --- FINALIZE & SAVE ---\n",
    "    updated_customers = [c for c in customers_dict.values()]\n",
    "    upd_df = pd.DataFrame(updated_customers)\n",
    "    upd_df['registration_date'] = pd.to_datetime(upd_df['registration_date']).dt.date\n",
    "    upd_df['last_order_date']   = pd.to_datetime(upd_df['last_order_date']).dt.date\n",
    "    upd_df.to_csv(STATIC_CUSTOMERS_CSV, index=False)\n",
    "\n",
    "    inv_new_df = pd.DataFrame(inventory_records_list)\n",
    "    inv_new_df.to_csv(INVENTORY_CSV, index=False)\n",
    "\n",
    "    return {\n",
    "        'orders': pd.DataFrame(all_orders),\n",
    "        'order_items': pd.DataFrame(all_items),\n",
    "        'delivery_performance': pd.DataFrame(all_perf),\n",
    "        'customer_feedback': pd.DataFrame(all_feedback),\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# Append or Save Data\n",
    "# -----------------------\n",
    "def append_or_save_data(df, filename):\n",
    "    try:\n",
    "        if os.path.exists(filename) and os.path.getsize(filename)>0:\n",
    "            df.to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv(filename, index=False)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing {filename}: {e}\")\n",
    "\n",
    "# -----------------------\n",
    "# Static Data Generation\n",
    "# -----------------------\n",
    "def generate_static_customers(num_customers=5405, start_id=5000):\n",
    "    customers = []\n",
    "    start_dt = date(2022, 1, 1)\n",
    "    end_dt   = date.today()\n",
    "\n",
    "    # 1) Build a registration-date list:\n",
    "    reg_dates = []\n",
    "    reg_dates += [start_dt] * min(200, num_customers)     # first 200 on Jan 1, 2022\n",
    "\n",
    "    cur_date = start_dt + timedelta(days=1)\n",
    "    while len(reg_dates) < num_customers and cur_date <= end_dt:\n",
    "        for _ in range(random.randint(2, 10)):\n",
    "            if len(reg_dates) < num_customers:\n",
    "                reg_dates.append(cur_date)\n",
    "        cur_date += timedelta(days=1)\n",
    "\n",
    "    # spill over to today if needed\n",
    "    while len(reg_dates) < num_customers:\n",
    "        reg_dates.append(end_dt)\n",
    "\n",
    "    # 2) Generate customer records in chronological order:\n",
    "    for cid, reg in zip(range(start_id, start_id + num_customers), reg_dates):\n",
    "        name = fake.name()\n",
    "\n",
    "        # Email based on name\n",
    "        local = name.lower().replace(\" \", \".\")\n",
    "        domain = random.choice([\"gmail.com\", \"yahoo.com\", \"outlook.com\"])\n",
    "        email = f\"{local}{random.randint(1,999)}@{domain}\"\n",
    "\n",
    "        # Indian mobile number +91 and 10 digits starting 6–9\n",
    "        phone = f\"+91{random.randint(6000000000, 9999999999)}\"\n",
    "        raw = fake.address().replace(\"\\n\", \", \")\n",
    "        # Split into components\n",
    "        parts = [p.strip() for p in raw.split(\",\") if p.strip()]\n",
    "        # street is first part, area is second if exists, else fallback\n",
    "        street = fake.street_name()\n",
    "        area = parts[1] if len(parts) > 1 else fake.street_name()\n",
    "        house_num = fake.building_number()\n",
    "        city = random.choices(CITY_LIST, weights=CITY_WEIGHTS)[0]\n",
    "        pincode_low, pincode_high = city_pincode_ranges[city]\n",
    "        pincode = random.randint(pincode_low, pincode_high)\n",
    "        full_addr = f\"{house_num} {street}, {area}\"\n",
    "        pin = pincode\n",
    "\n",
    "        customers.append({\n",
    "            'customer_id': cid,\n",
    "            'customer_name': name,\n",
    "            'email': email,\n",
    "            'phone': phone,\n",
    "            'address': full_addr,\n",
    "            'area': area,\n",
    "            'city': city,\n",
    "            'pincode': pin,\n",
    "            'registration_date': reg,\n",
    "            'total_orders': 0,\n",
    "            'avg_order_value': 0,\n",
    "            'last_order_date': reg,\n",
    "            'segmentation': 'New'\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(customers)\n",
    "\n",
    "\n",
    "def generate_static_products(num_products_per_category=40):\n",
    "    fixed_specs = {\n",
    "        'Fruits & Vegetables':   {'min_stock_level': 2,  'max_stock_level': 18,  'margin_pct_range': (60, 80),  'shelf_life_days': 3},\n",
    "        'Dairy & Breakfast':     {'min_stock_level': 2,  'max_stock_level': 50,  'margin_pct_range': (15, 25),  'shelf_life_days': 7},\n",
    "        'Snacks & Munchies':     {'min_stock_level': 20, 'max_stock_level': 600, 'margin_pct_range': (12, 18),  'shelf_life_days': 120},\n",
    "        'Cold Drinks & Juices':  {'min_stock_level': 10, 'max_stock_level': 250, 'margin_pct_range': (10, 15),  'shelf_life_days': 90},\n",
    "        'Instant & Frozen Food': {'min_stock_level': 10, 'max_stock_level': 390, 'margin_pct_range': (8, 12),   'shelf_life_days': 90},\n",
    "        'Grocery & Staples':     {'min_stock_level': 5,  'max_stock_level': 1100,'margin_pct_range': (8, 12),   'shelf_life_days': 90},\n",
    "        'Household Care':        {'min_stock_level': 10, 'max_stock_level': 660, 'margin_pct_range': (40, 50),  'shelf_life_days': 250},\n",
    "        'Personal Care':         {'min_stock_level': 25, 'max_stock_level': 500, 'margin_pct_range': (30, 40),  'shelf_life_days': 300},\n",
    "        'Baby Care':             {'min_stock_level': 10, 'max_stock_level': 160, 'margin_pct_range': (25, 35),  'shelf_life_days': 150},\n",
    "        'Pet Care':              {'min_stock_level': 8,  'max_stock_level': 140, 'margin_pct_range': (40, 50),  'shelf_life_days': 240},\n",
    "        'Pharmacy':              {'min_stock_level': 10, 'max_stock_level': 1000,'margin_pct_range': (55, 65),  'shelf_life_days': 300}\n",
    "    }\n",
    "\n",
    "    category_products = {\n",
    "        'Fruits & Vegetables': ['Banana', 'Tomato', 'Onion', 'Potato', 'Mango', 'Apple', 'Cucumber', 'Carrot', 'Spinach', 'Cabbage', 'Ginger', 'Garlic', 'Lemon', 'Coriander', 'Green Chili'],\n",
    "        'Dairy & Breakfast': ['Amul Milk', 'Mother Dairy Milk', 'Amul Butter', 'Amul Ghee', 'Mother Dairy Paneer', 'Eggs', 'Bread', 'Dahi', 'Mix Dosa', 'Mix Upma', 'Mix Poha', 'Cheese Slices', 'Curd', 'Butter Milk', 'Flavored Yogurt'],\n",
    "        'Snacks & Munchies': ['Lays Chips', 'Kurkure', 'Haldiram Namkeen', 'Parle-G Biscuits', 'Hide & Seek', 'Bingo Chips', 'Perk', 'Munch', 'Oreo', 'Marie Gold', 'Unibic Cookies', 'Britannia Cake', 'Popcorn', 'Nachos', 'Trail Mix'],\n",
    "        'Cold Drinks & Juices': ['Coca-Cola', 'Pepsi', 'Thums Up', 'Sprite', 'Fanta', 'Maaza', 'Slice', 'Frooti', 'Real Juice', 'Tropicana', 'Bisleri Water', 'Kinley Water', 'Red Bull', 'Appy Fizz', 'Bournvita'],\n",
    "        'Instant & Frozen Food': ['Maggi Noodles', 'Yippee Noodles', 'Frozen Paratha', 'Frozen Pizza', 'Frozen French Fries', 'Frozen Momos', 'Ready-to-Eat Meals', 'Instant Pasta', 'Frozen Vegetables', 'Frozen Chicken Nuggets', 'Frozen Fish Fingers', 'Instant Soup', 'Frozen Samosa', 'Frozen Spring Rolls', 'Frozen Paneer Tikka'],\n",
    "        'Grocery & Staples': ['Aashirvaad Atta', 'Fortune Rice', 'Tata Salt', 'Sugar', 'Toor Dal', 'Chana Dal', 'Moong Dal', 'Masoor Dal', 'Fortune Oil', 'Saffola Oil', 'Tata Tea', 'Nescafe Coffee', 'Catch Spices', 'Everest Masala', 'MDH Masala'],\n",
    "        'Household Care': ['Surf Excel Detergent', 'Ariel Detergent', 'Vim Dishwash Gel', 'Harpic Toilet Cleaner', 'Lizol Floor Cleaner', 'Colin Glass Cleaner', 'Odonil Air Freshener', 'Domex Disinfectant', 'Dettol Antiseptic', 'Scotch-Brite Scrub Pad', 'Garbage Bags', 'Room Freshener', 'Naphthalene Balls', 'Toilet Brush', 'Mop'],\n",
    "        'Personal Care': ['Colgate Toothpaste', 'Pepsodent Toothpaste', 'Dabur Red Toothpaste', 'Clinic Plus Shampoo', 'Sunsilk Shampoo', 'Dove Soap', 'Lifebuoy Soap', 'Dettol Soap', 'Nivea Body Lotion', 'Patanjali Face Wash', 'Himalaya Face Wash', 'Veet Hair Removal Cream', 'Whisper Sanitary Pads', 'Stayfree Sanitary Pads', 'Pears Soap'],\n",
    "        'Baby Care': ['Pampers Diapers', 'Huggies Diapers', 'Johnson Baby Lotion', 'Johnson Baby Shampoo', 'Johnson Baby Powder', 'Baby Wipes', 'Cerelac', 'Farex', 'Lactogen', 'Nestle Nan Pro', 'Baby Oil', 'Baby Cream', 'Baby Soap', 'Baby Feeding Bottle', 'Baby Pacifier'],\n",
    "        'Pet Care': ['Pedigree Dog Food', 'Whiskas Cat Food', 'Drools Dog Food', 'Me-O Cat Food', 'Pet Shampoo', 'Pet Treats', 'Pet Toys', 'Pet Bed', 'Pet Collar', 'Pet Leash', 'Pet Bowls', 'Pet Litter', 'Pet Cage', 'Pet Vitamins', 'Pet Brush'],\n",
    "        'Pharmacy': ['Paracetamol', 'Crocin', 'Dolo 650', 'Vicks Vaporub', 'Dabur Honitus', 'Zandu Balm', 'Eno', 'Digene', 'ORS Sachets', 'Band-Aid', 'Dettol Antiseptic Liquid', 'Thermometer', 'Sanitizer', 'Face Mask', 'Multivitamin Tablets']\n",
    "    }\n",
    "\n",
    "    product_mrp_map = {'Banana':32, 'Tomato':28, 'Onion':40, 'Potato':20, 'Mango':30, 'Apple':100, 'Cucumber':26, 'Carrot':25, 'Spinach':20, 'Cabbage':20, 'Ginger':120, 'Garlic':160, 'Lemon':100, 'Coriander':80, 'Green Chili':90, 'Amul Milk':40, 'Mother Dairy Milk':52, 'Amul Butter':56, 'Amul Ghee':520, 'Mother Dairy Paneer':70, 'Eggs':84, 'Bread':35, 'Dahi':50, 'Mix Dosa':30, 'Mix Upma':30, 'Mix Poha':30, 'Cheese Slices':80, 'Curd':50, 'Butter Milk':35, 'Flavored Yogurt':25, 'Lays Chips':30, 'Kurkure':20, 'Haldiram Namkeen':50, 'Parle-G Biscuits':40, 'Hide & Seek':20, 'Bingo Chips':20, 'Perk':20, 'Munch':20, 'Oreo':45, 'Marie Gold':20, 'Unibic Cookies':30, 'Britannia Cake':20, 'Popcorn':25, 'Nachos':25, 'Trail Mix':120, 'Coca-Cola':40, 'Pepsi':40, 'Thums Up':35, 'Sprite':40, 'Fanta':40, 'Maaza':30, 'Slice':30, 'Frooti':25, 'Real Juice':150, 'Tropicana':170, 'Bisleri Water':20, 'Kinley Water':20, 'Red Bull':80, 'Appy Fizz':40, 'Bournvita':200, 'Maggi Noodles':20, 'Yippee Noodles':20, 'Frozen Paratha':80, 'Frozen Pizza':150, 'Frozen French Fries':100, 'Frozen Momos':120, 'Ready-to-Eat Meals':180, 'Instant Pasta':60, 'Frozen Vegetables':80, 'Frozen Chicken Nuggets':160, 'Frozen Fish Fingers':140, 'Instant Soup':50, 'Frozen Samosa':40, 'Frozen Spring Rolls':50, 'Frozen Paneer Tikka':200, 'Aashirvaad Atta':55, 'Fortune Rice':60, 'Tata Salt':30, 'Sugar':45, 'Toor Dal':150, 'Chana Dal':120, 'Moong Dal':140, 'Masoor Dal':130, 'Fortune Oil':180, 'Saffola Oil':200, 'Tata Tea':80, 'Nescafe Coffee':100, 'Catch Spices':60, 'Everest Masala':50, 'MDH Masala':45, 'Surf Excel Detergent':60, 'Ariel Detergent':90, 'Vim Dishwash Gel':80, 'Harpic Toilet Cleaner':70, 'Lizol Floor Cleaner':80, 'Colin Glass Cleaner':70, 'Odonil Air Freshener':40, 'Domex Disinfectant':80, 'Dettol Antiseptic':120, 'Scotch-Brite Scrub Pad':40, 'Garbage Bags':60, 'Room Freshener':80, 'Naphthalene Balls':30, 'Toilet Brush':150, 'Mop':200, 'Colgate Toothpaste':80, 'Pepsodent Toothpaste':60, 'Dabur Red Toothpaste':60, 'Clinic Plus Shampoo':80, 'Sunsilk Shampoo':90, 'Dove Soap':70, 'Lifebuoy Soap':25, 'Dettol Soap':40, 'Nivea Body Lotion':200, 'Patanjali Face Wash':60, 'Himalaya Face Wash':80, 'Veet Hair Removal Cream':150, 'Whisper Sanitary Pads':60, 'Stayfree Sanitary Pads':50, 'Pears Soap':50, 'Pampers Diapers':300, 'Huggies Diapers':250, 'Johnson Baby Lotion':150, 'Johnson Baby Shampoo':120, 'Johnson Baby Powder':100, 'Baby Wipes':80, 'Cerelac':150, 'Farex':200, 'Lactogen':150, 'Nestle Nan Pro':500, 'Baby Oil':100, 'Baby Cream':200, 'Baby Soap':30, 'Baby Feeding Bottle':150, 'Baby Pacifier':100, 'Pedigree Dog Food':200, 'Whiskas Cat Food':220, 'Drools Dog Food':180, 'Me-O Cat Food':200, 'Pet Shampoo':150, 'Pet Treats':50, 'Pet Toys':200, 'Pet Bed':500, 'Pet Collar':100, 'Pet Leash':150, 'Pet Bowls':200, 'Pet Litter':250, 'Pet Cage':1500, 'Pet Vitamins':300, 'Pet Brush':100, 'Paracetamol':20, 'Crocin':30, 'Dolo 650':35, 'Vicks Vaporub':50, 'Dabur Honitus':40, 'Zandu Balm':30, 'Eno':20, 'Digene':20, 'ORS Sachets':20, 'Band-Aid':40, 'Dettol Antiseptic Liquid':120, 'Thermometer':200, 'Sanitizer':100, 'Face Mask':50, 'Multivitamin Tablets':200}\n",
    "\n",
    "\n",
    "    products = []\n",
    "    product_id_counter = 1000\n",
    "\n",
    "    for cat, items in category_products.items():\n",
    "        specs = fixed_specs[cat]\n",
    "        for name in items:\n",
    "            mrp = product_mrp_map[name]\n",
    "            low_margin, high_margin = specs['margin_pct_range']\n",
    "            base_margin_pct = round(random.uniform(low_margin, high_margin), 2)\n",
    "            base_purchase_cost = round(mrp * (1 - base_margin_pct/100), 2)\n",
    "            products.append({\n",
    "                'product_id': product_id_counter,\n",
    "                'product_name': name,\n",
    "                'category': cat,\n",
    "                'brand': fake.company(),\n",
    "                'mrp': mrp,\n",
    "                'base_margin_pct': base_margin_pct,\n",
    "                'base_purchasing_cost': base_purchase_cost,\n",
    "                'shelf_life_days': specs['shelf_life_days'],\n",
    "                'min_stock_level': specs['min_stock_level'],\n",
    "                'max_stock_level': specs['max_stock_level']\n",
    "            })\n",
    "            product_id_counter += 1\n",
    "\n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "def generate_marketing_performance(start_date_str='2022-01-01', end_date=None):\n",
    "    if end_date is None:\n",
    "        end_date = date.today()\n",
    "    start_date = datetime.strptime(start_date_str, '%Y-%m-%d').date()\n",
    "    date_range_days = (end_date - start_date).days\n",
    "    segmentation_list = [\"Premium\", \"Inactive\", \"New\", \"Regular\"]\n",
    "    campaign_info = {\n",
    "        \"Premium\": {\"campaign_name\": \"Exclusive Premium Offers\", \"frequency\": 1, \"channel\": \"Email\"},\n",
    "        \"Inactive\": {\"campaign_name\": \"We Miss You - Come Back\", \"frequency\": 3, \"channel\": \"SMS\"},\n",
    "        \"New\": {\"campaign_name\": \"Welcome Offer\", \"frequency\": 2, \"channel\": \"App\"},\n",
    "        \"Regular\": {\"campaign_name\": \"Thank You - Special Deals\", \"frequency\": 2, \"channel\": \"Email\"}\n",
    "    }\n",
    "    marketing_data = []\n",
    "    campaign_id = 1\n",
    "    for day in range(0, date_range_days + 1, 7):\n",
    "        current_date = start_date + timedelta(days=day)\n",
    "        for seg in segmentation_list:\n",
    "            info = campaign_info[seg]\n",
    "            spend = round(random.uniform(40000, 70000), 2)\n",
    "            revenue = round(random.uniform(80000, 100000), 2)\n",
    "            marketing_data.append({\n",
    "                'campaign_id': campaign_id,\n",
    "                'campaign_name': info['campaign_name'],\n",
    "                'date': current_date - timedelta(days=1),\n",
    "                'target_segmentation': seg,\n",
    "                'frequency': info['frequency'],\n",
    "                'channel': info['channel'],\n",
    "                'impressions': random.randint(2000, 4000),\n",
    "                'clicks': random.randint(900, 2000),\n",
    "                'conversions': random.randint(100, 300),\n",
    "                'spend': spend,\n",
    "                'revenue_generated': revenue,\n",
    "                'roas': round(revenue / spend, 2)\n",
    "            })\n",
    "            campaign_id += 1\n",
    "    return pd.DataFrame(marketing_data)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Main Execution\n",
    "# -----------------------\n",
    "if __name__ == '__main__':\n",
    "    # Generate static customers\n",
    "    if not os.path.exists(STATIC_CUSTOMERS_CSV) or os.path.getsize(STATIC_CUSTOMERS_CSV) == 0:\n",
    "        cust_df = generate_static_customers()\n",
    "        cust_df.to_csv(STATIC_CUSTOMERS_CSV, index=False)\n",
    "\n",
    "    # Generate static products\n",
    "    if not os.path.exists(STATIC_PRODUCTS_CSV) or os.path.getsize(STATIC_PRODUCTS_CSV) == 0:\n",
    "        prod_df = generate_static_products()\n",
    "        prod_df.to_csv(STATIC_PRODUCTS_CSV, index=False)\n",
    "\n",
    "    # Generate marketing performance\n",
    "    if not os.path.exists(MARKETING_PERFORMANCE_CSV) or os.path.getsize(MARKETING_PERFORMANCE_CSV) == 0:\n",
    "        mp_df = generate_marketing_performance(DEFAULT_START_DATE, date.today())\n",
    "        mp_df.to_csv(MARKETING_PERFORMANCE_CSV, index=False)\n",
    "\n",
    "    # Initialize inventory if needed\n",
    "    if not os.path.exists(INVENTORY_CSV) or os.path.getsize(INVENTORY_CSV) == 0:\n",
    "        static_prod_df = pd.read_csv(STATIC_PRODUCTS_CSV)\n",
    "        inv_df = initialize_inventory(static_prod_df, datetime.strptime(DEFAULT_START_DATE, '%Y-%m-%d').date())\n",
    "        inv_df.to_csv(INVENTORY_CSV, index=False)\n",
    "\n",
    "    # Generate and append daily orders\n",
    "    start_date, end_date = get_new_date_range(ORDERS_CSV, DEFAULT_START_DATE)\n",
    "    if start_date <= end_date:\n",
    "        # Unchanged: generate orders, order_items, delivery_performance, customer_feedback\n",
    "        new_data = generate_new_daily_orders(start_date, end_date)\n",
    "        # Append orders etc.\n",
    "        append_or_save_data(new_data['orders'], ORDERS_CSV)\n",
    "        append_or_save_data(new_data['order_items'], ORDER_ITEMS_CSV)\n",
    "        append_or_save_data(new_data['delivery_performance'], DELIVERY_PERFORMANCE_CSV)\n",
    "        append_or_save_data(new_data['customer_feedback'], CUSTOMER_FEEDBACK_CSV)\n",
    "        # After orders for each day, update inventory:\n",
    "        current = start_date\n",
    "        all_inv_records = []\n",
    "        while current <= end_date:\n",
    "            daily_rows = update_inventory_record_for_day(current, products_dict, inventory_dict)\n",
    "            all_inv_records.extend(daily_rows)\n",
    "            current += timedelta(days=1)\n",
    "        inv_new_df = pd.DataFrame(all_inv_records)\n",
    "        inv_new_df = inv_new_df[[\n",
    "            'product_id', 'date', 'mrp', 'price', 'purchasing_cost', 'Selling Cost',\n",
    "            'profit', 'new_stock', 'start_available_stock', 'sold_stock',\n",
    "            'end_available_stock', 'damaged_stock'\n",
    "        ]]\n",
    "        inv_new_df.to_csv(INVENTORY_CSV, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        logging.info(\"No new days to process for orders.\")\n",
    "    # Clean up seed inventory row for 2021-12-31 after file generation\n",
    "if os.path.exists(INVENTORY_CSV):\n",
    "    inventory_df = pd.read_csv(INVENTORY_CSV, parse_dates=['date'])\n",
    "    inventory_df = inventory_df[inventory_df['date'] != pd.Timestamp(\"2021-12-31\")]\n",
    "    inventory_df.to_csv(INVENTORY_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category-level damage percentages:\n",
      "             category  total_received_stock  total_damaged_stock  damage_percent\n",
      "            Baby Care                 26528                 2132        8.036791\n",
      " Cold Drinks & Juices                 73406                 1609        2.191919\n",
      "    Dairy & Breakfast                205553                 4986        2.425652\n",
      "  Fruits & Vegetables                168504                12119        7.192114\n",
      "    Grocery & Staples                309884                 9469        3.055660\n",
      "       Household Care                 67828                 3288        4.847556\n",
      "Instant & Frozen Food                111850                 3572        3.193563\n",
      "        Personal Care                 42500                 3033        7.136471\n",
      "             Pet Care                 14387                 1540       10.704108\n",
      "             Pharmacy                 83362                 4873        5.845589\n",
      "    Snacks & Munchies                130078                 4731        3.637049\n",
      "\n",
      "Categories with damage between 8% and 10%:\n",
      " category  damage_percent\n",
      "Baby Care        8.036791\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Load your data\n",
    "inv_df  = pd.read_csv('Apna_inventory.csv', parse_dates=['date'])\n",
    "prod_df = pd.read_csv('Apna_products.csv')\n",
    "\n",
    "# 2) Attach category to each inventory row\n",
    "inv_cat = inv_df.merge(\n",
    "    prod_df[['product_id', 'category']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3) Aggregate per category\n",
    "#    - total_received_stock: sum of all 'new_stock' arrivals (includes initial stock)\n",
    "#    - total_damaged_stock : sum of all 'damaged_stock' recorded\n",
    "received = (\n",
    "    inv_cat\n",
    "    .groupby('category', as_index=False)['new_stock']\n",
    "    .sum()\n",
    "    .rename(columns={'new_stock': 'total_received_stock'})\n",
    ")\n",
    "damaged = (\n",
    "    inv_cat\n",
    "    .groupby('category', as_index=False)['damaged_stock']\n",
    "    .sum()\n",
    "    .rename(columns={'damaged_stock': 'total_damaged_stock'})\n",
    ")\n",
    "\n",
    "# 4) Merge and compute damage percentage\n",
    "agg = pd.merge(received, damaged, on='category')\n",
    "agg['damage_percent'] = (\n",
    "    agg['total_damaged_stock'] / agg['total_received_stock']\n",
    ") * 100\n",
    "\n",
    "# 5) Which categories hit your 8–10% damage target?\n",
    "within_8_10 = agg[\n",
    "    (agg['damage_percent'] >= 8.0) &\n",
    "    (agg['damage_percent'] <= 10.0)\n",
    "]\n",
    "\n",
    "# 6) Display results\n",
    "print(\"\\nCategory-level damage percentages:\")\n",
    "print(agg[['category','total_received_stock','total_damaged_stock','damage_percent']]\n",
    "      .to_string(index=False))\n",
    "\n",
    "print(\"\\nCategories with damage between 8% and 10%:\")\n",
    "print(within_8_10[['category','damage_percent']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing master table found. Creating a new one.\n",
      "Data types in the master table:\n",
      "Date                             object\n",
      "order_id                          int64\n",
      "order_date               datetime64[ns]\n",
      "order_status                     object\n",
      "delivery_partner_id               int64\n",
      "payment_method                   object\n",
      "customer_name                    object\n",
      "city                             object\n",
      "customer_segment                 object\n",
      "pincode                           int64\n",
      "customer_id                       int64\n",
      "product_id                        int64\n",
      "product_name                     object\n",
      "category                         object\n",
      "price                             int64\n",
      "feedback_id                       int64\n",
      "quantity                          int64\n",
      "Value                             int64\n",
      "rating                            int64\n",
      "feedback_category                object\n",
      "sentiment                        object\n",
      "feedback_text                    object\n",
      "delivery_status                  object\n",
      "promised_time            datetime64[ns]\n",
      "actual_time              datetime64[ns]\n",
      "delivery_time_minutes           float64\n",
      "reasons_if_delayed               object\n",
      "Img                              object\n",
      "Emoji                            object\n",
      "Star                             object\n",
      "dtype: object\n",
      "Master table updated and saved to Master_Table.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    # -----------------------\n",
    "    # File Paths\n",
    "    # -----------------------\n",
    "    ORDERS_CSV = 'Apna_orders.csv'\n",
    "    ORDER_ITEMS_CSV = 'Apna_order_items.csv'\n",
    "    DELIVERY_PERFORMANCE_CSV = 'Apna_delivery_performance.csv'\n",
    "    CUSTOMER_FEEDBACK_CSV = 'Apna_customer_feedback.csv'\n",
    "    STATIC_PRODUCTS_CSV = 'Apna_products.csv'\n",
    "    STATIC_CUSTOMERS_CSV = 'Apna_customers.csv'\n",
    "    \n",
    "    # External lookup files (Excel)\n",
    "    RATING_ICONS_XLSX = 'rating_Icon.xlsx'       # Contains: Rating, Emoji, Star\n",
    "    CATEGORY_ICONS_XLSX = 'category_Icons.xlsx'   # Contains: category, Img\n",
    "    \n",
    "    # Output Master Table CSV file\n",
    "    MASTER_TABLE_CSV = 'Master_Table.csv'\n",
    "    \n",
    "    # -----------------------\n",
    "    # Read Input Files with proper parsing\n",
    "    # -----------------------\n",
    "    orders = pd.read_csv(ORDERS_CSV, parse_dates=['order_date'])\n",
    "    order_items = pd.read_csv(ORDER_ITEMS_CSV)\n",
    "    delivery_perf = pd.read_csv(DELIVERY_PERFORMANCE_CSV, parse_dates=['promised_time', 'actual_time'])\n",
    "    customer_fb = pd.read_csv(CUSTOMER_FEEDBACK_CSV, parse_dates=['feedback_date'])\n",
    "    products = pd.read_csv(STATIC_PRODUCTS_CSV)\n",
    "    customers = pd.read_csv(STATIC_CUSTOMERS_CSV, parse_dates=['registration_date', 'last_order_date'])\n",
    "    \n",
    "    # Read Excel lookup tables\n",
    "    rating_icons = pd.read_excel(RATING_ICONS_XLSX, engine='openpyxl')\n",
    "    category_icons = pd.read_excel(CATEGORY_ICONS_XLSX, engine='openpyxl')\n",
    "    \n",
    "    # -----------------------\n",
    "    # Load Existing Master Table (if available)\n",
    "    # -----------------------\n",
    "    if os.path.exists(MASTER_TABLE_CSV) and os.path.getsize(MASTER_TABLE_CSV) > 0:\n",
    "        master_df_existing = pd.read_csv(MASTER_TABLE_CSV, parse_dates=['order_date'])\n",
    "        last_master_date = master_df_existing['order_date'].max()\n",
    "        print(\"Existing master table found. Last order date:\", last_master_date)\n",
    "    else:\n",
    "        master_df_existing = None\n",
    "        last_master_date = None\n",
    "        print(\"No existing master table found. Creating a new one.\")\n",
    "    \n",
    "    # -----------------------\n",
    "    # Filter for New Orders\n",
    "    # -----------------------\n",
    "    if last_master_date is not None:\n",
    "        new_orders = orders[orders['order_date'] > last_master_date].copy()\n",
    "    else:\n",
    "        new_orders = orders.copy()\n",
    "    \n",
    "    if new_orders.empty:\n",
    "        print(\"No new orders found to append.\")\n",
    "        return\n",
    "    \n",
    "    # -----------------------\n",
    "    # Merge DataFrames to Build New Data Portion\n",
    "    # -----------------------\n",
    "    # 1. Merge new orders with order_items on order_id.\n",
    "    df_new = new_orders.merge(order_items, on='order_id', how='left')\n",
    "    \n",
    "    # 2. Merge with products on product_id.\n",
    "    df_new = df_new.merge(products, on='product_id', how='left', suffixes=('', '_prod'))\n",
    "    \n",
    "    # 3. Rename customers' 'segmentation' column and merge on customer_id.\n",
    "    customers.rename(columns={'segmentation': 'customer_segment'}, inplace=True)\n",
    "    df_new = df_new.merge(customers, on='customer_id', how='left', suffixes=('', '_cust'))\n",
    "    \n",
    "    # 4. Merge with customer feedback on order_id and customer_id.\n",
    "    df_new = df_new.merge(customer_fb, on=['order_id', 'customer_id'], how='left', suffixes=('', '_fb'))\n",
    "    \n",
    "    # 5. Merge with delivery performance on order_id.\n",
    "    df_new = df_new.merge(delivery_perf, on='order_id', how='left', suffixes=('', '_dp'))\n",
    "    \n",
    "    # 6. Merge with rating icons (to add Emoji and Star) using rating.\n",
    "    df_new = df_new.merge(rating_icons, left_on='rating', right_on='Rating', how='left')\n",
    "    \n",
    "    # 7. Merge with category icons on product category.\n",
    "    df_new = df_new.merge(category_icons, on='category', how='left')\n",
    "    \n",
    "    # -----------------------\n",
    "    # Prepare New Master Data\n",
    "    # -----------------------\n",
    "    # Create a date-only column (from order_date)\n",
    "    df_new['Date'] = df_new['order_date'].dt.date\n",
    "\n",
    "    # Select and rename columns.\n",
    "    # Note: The original selection expected a 'price' column but order_items provides 'unit_price'.\n",
    "    # We select 'unit_price' and then rename it to 'price' for consistency.\n",
    "    master_new = df_new[['Date',\n",
    "                         'order_id',\n",
    "                         'order_date',\n",
    "                         'order_status',\n",
    "                         'delivery_partner_id',\n",
    "                         'payment_method',\n",
    "                         'customer_name',\n",
    "                         'city',\n",
    "                         'customer_segment',\n",
    "                         'pincode',\n",
    "                         'customer_id',\n",
    "                         'product_id',\n",
    "                         'product_name',\n",
    "                         'category',\n",
    "                         'unit_price',\n",
    "                         'feedback_id',\n",
    "                         'quantity',\n",
    "                         'total_price',   # Will be renamed to 'Value'\n",
    "                         'rating',\n",
    "                         'feedback_category',\n",
    "                         'sentiment',\n",
    "                         'feedback_text',\n",
    "                         'delivery_status',\n",
    "                         'promised_time',\n",
    "                         'actual_time',\n",
    "                         'delivery_time_minutes',\n",
    "                         'reasons_if_delayed',\n",
    "                         'Img',\n",
    "                         'Emoji',\n",
    "                         'Star'               \n",
    "                         ]].copy()\n",
    "    \n",
    "    # Rename columns as needed\n",
    "    master_new.rename(columns={'unit_price': 'price', 'total_price': 'Value'}, inplace=True)\n",
    "    \n",
    "    # -----------------------\n",
    "    # Enforce Correct Data Types\n",
    "    # -----------------------\n",
    "    master_new['order_date'] = pd.to_datetime(master_new['order_date'], errors='coerce')\n",
    "    if 'promised_time' in master_new.columns:\n",
    "        master_new['promised_time'] = pd.to_datetime(master_new['promised_time'], errors='coerce')\n",
    "    if 'actual_time' in master_new.columns:\n",
    "        master_new['actual_time'] = pd.to_datetime(master_new['actual_time'], errors='coerce')\n",
    "    \n",
    "    for col in ['price', 'quantity', 'Value', 'delivery_time_minutes']:\n",
    "        if col in master_new.columns:\n",
    "            master_new[col] = pd.to_numeric(master_new[col], errors='coerce')\n",
    "    \n",
    "    # -----------------------\n",
    "    # Append New Data to Existing Master Table\n",
    "    # -----------------------\n",
    "    if master_df_existing is not None:\n",
    "        master_df_existing['order_date'] = pd.to_datetime(master_df_existing['order_date'], errors='coerce')\n",
    "        master_updated = pd.concat([master_df_existing, master_new], ignore_index=True)\n",
    "    else:\n",
    "        master_updated = master_new\n",
    "\n",
    "    master_updated.sort_values(by='order_date', inplace=True)\n",
    "    \n",
    "    print(\"Data types in the master table:\")\n",
    "    print(master_updated.dtypes)\n",
    "    \n",
    "    master_updated.to_csv(MASTER_TABLE_CSV, index=False)\n",
    "    print(\"Master table updated and saved to\", MASTER_TABLE_CSV)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing master inventory found. Creating a new one.\n",
      "Inventory master table has been updated and saved to Inventory_Master_Table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# File Paths\n",
    "# -----------------------\n",
    "STATIC_PRODUCTS_CSV = 'Apna_products.csv'\n",
    "INVENTORY_CSV = 'Apna_inventory.csv'\n",
    "INVENTORY_MASTER_CSV = 'Inventory_Master_Table.csv'  # Using CSV for the master inventory\n",
    "\n",
    "# -----------------------\n",
    "# Read the Data Files\n",
    "# -----------------------\n",
    "# Read the products data\n",
    "products = pd.read_csv(STATIC_PRODUCTS_CSV)\n",
    "\n",
    "# Read the inventory data, parsing the 'date' column as a datetime.\n",
    "inventory = pd.read_csv(INVENTORY_CSV, parse_dates=['date'])\n",
    "\n",
    "# -----------------------\n",
    "# Load Existing Master Inventory (if available)\n",
    "# -----------------------\n",
    "if os.path.exists(INVENTORY_MASTER_CSV) and os.path.getsize(INVENTORY_MASTER_CSV) > 0:\n",
    "    master_inventory_existing = pd.read_csv(INVENTORY_MASTER_CSV, parse_dates=['date'])\n",
    "    last_inventory_date = master_inventory_existing['date'].max()\n",
    "    print(\"Existing master inventory found. Last inventory date:\", last_inventory_date)\n",
    "else:\n",
    "    master_inventory_existing = None\n",
    "    last_inventory_date = None\n",
    "    print(\"No existing master inventory found. Creating a new one.\")\n",
    "\n",
    "# -----------------------\n",
    "# Filter for New Inventory Data\n",
    "# -----------------------\n",
    "if last_inventory_date is not None:\n",
    "    new_inventory = inventory[inventory['date'] > last_inventory_date].copy()\n",
    "else:\n",
    "    new_inventory = inventory.copy()\n",
    "\n",
    "if new_inventory.empty:\n",
    "    print(\"No new inventory data to append. Exiting.\")\n",
    "    exit(0)\n",
    "\n",
    "# -----------------------\n",
    "# Merge New Inventory Data with Products\n",
    "# -----------------------\n",
    "# Join new inventory records with product details based on product_id.\n",
    "inventory_master_new = pd.merge(\n",
    "    new_inventory,\n",
    "    products,\n",
    "    on='product_id',\n",
    "    how='left',\n",
    "    suffixes=('', '_prod')\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Select and Order Columns for the Master Inventory Table\n",
    "# -----------------------\n",
    "selected_columns = [\n",
    "    'date',                  \n",
    "    'product_id',            \n",
    "    'product_name',          \n",
    "    'category',              \n",
    "    'price',                 \n",
    "    'mrp',                   \n",
    "    'purchasing_cost',       \n",
    "    'Selling Cost',\n",
    "    'profit',\n",
    "    'new_stock',\n",
    "    'start_available_stock',\n",
    "    'sold_stock',\n",
    "    'end_available_stock',\n",
    "    'damaged_stock'\n",
    "]\n",
    "\n",
    "inventory_master_new = inventory_master_new[selected_columns]\n",
    "\n",
    "# -----------------------\n",
    "# Append New Data to the Existing Master Inventory Table\n",
    "# -----------------------\n",
    "if master_inventory_existing is not None:\n",
    "    master_inventory_updated = pd.concat(\n",
    "        [master_inventory_existing, inventory_master_new],\n",
    "        ignore_index=True\n",
    "    )\n",
    "else:\n",
    "    master_inventory_updated = inventory_master_new\n",
    "\n",
    "# -----------------------\n",
    "# ROUND & CAST ALL NUMERIC COLUMNS TO INTEGER\n",
    "# -----------------------\n",
    "# Identify all numeric columns\n",
    "num_cols = master_inventory_updated.select_dtypes(include='number').columns\n",
    "\n",
    "# Round to nearest integer and cast to int\n",
    "master_inventory_updated[num_cols] = (\n",
    "    master_inventory_updated[num_cols]\n",
    "    .round(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Save the Updated Master Inventory Table to CSV\n",
    "# -----------------------\n",
    "master_inventory_updated.to_csv(INVENTORY_MASTER_CSV, index=False)\n",
    "print(\"Inventory master table has been updated and saved to\", INVENTORY_MASTER_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
